
머신 러닝
====


딥러닝이 가능한 3가지
> 빅데이터
 GPU
 알고리즘 : ????


#### 컴퓨터에게 그림을 주고 개인지 고양이인지 판단하는 프로그램을 작성하시오

- ????

##### 딥러닝으로 코드 만들기

VGG16 모델 만들기


기존의 코딩 : 조건을 라인바이 라인으로 긴 코드로 써내려 가는 일
앞으로 : 조건을 학습 모델의 여러 가중치로 변환하는 일

VGG 16 ??
 - 간단한 코드로 영상 인식을 할 수 있다.


사람의 뇌신경을 닮은 뉴럴네트워크이니 사람만큼 잘 할 수 있으가?

> 덜하거나 : 학습을 잘 하지 못한다.
> 느리거나 : 학습이 오래 걸린다.
> 과하거나 : 되어도 잘 맞추기 힘들다.

이걸 해결해 보자

뉴럴네스이 학습방법 : BackPropagation

- 무엇을 뒤로 전달한다는 걸까?
- 내가 틀린 정도를 미분 한 것

그런데 문제는?

#### 학습이 잘 안돼...
기울기가 0인 부분에 걸리면 업데이트가 사라져간다 : Vanishing gradient 현상
- 그래서 fitting이 잘 안됨

사그러드는 sigmoid 대신 죽지않는 active function을 쓰자!!
=> ReLU(Rectified Linear Units)

![](https://i.imgur.com/7ce8Zr6.png)
양의 구간에서 전부 미분값(1)이 있다!! : 뒷 줄 까지 학습이 잘 날아가게 해준다.

##### 전달하다가 사그라져 버린다(Vanishing grandiet)

##### 해결!
- sigmoid -> ReLU = 뒤로 전달되게 한다.


#### 느린거

##### 기존 뉴럴네싱 가중치 parameter 들을 최적화하는 방법
- Gradient Decent
  - loss function의 현 가중치에서의 기울기를 구해 loss를 줄이는 방향을 업데이트해 나간다.
- loss fuction : 트레이닝에서 weight를 바꿔나가는 방식으로 학습하낟.
  - 뉴럴넷은 loss funciton을 가지고 있다 - 틀린 정도
- 현재 가진 weight 세팅에서 내가 가진 데이터를 다 넣으며 나오는 에러마다 미분한 값의 평균으로 전체 에러를 주링는 방향을 알 수 있따 : 내자리의 기울기 * 반대방향
- weight를 바꿔감에 따라 낮아지는 지점이 있다.

##### 내가 가진 데이터를 다 넣으면서 ???
- 내가 가진 데이터가 몇 억건이면? : 어느세월에 다할까
- GD ㅗㅂ다 빠른 옵티마이저는 없을까?

##### SGD : 느린 완벽보다 조금만 훑어보고 일단 빨리 가봅시다.
Stochastic Gradient Decent

- GD : 전부 읽고나서 최적의 1스텝 간다. : full-batch
- SGD : 작은 토막마다 일단 1스텝 간다 : mini-batch
  - 작은 단위로 더 자주
  - 문제 : 적은 데이터로 잘못 판단할 수도 있다.


##### 문제 : 걸음마다 batch로 전부 다 계산하려니 GD가 너무 오래걸린다

##### - 해결
- SGD로 mini-batch마다 움직여 같은 시간에 훨씬 더 많이 진행시켜 해결!

그러나 mini-batch의 문제점
- 훨씬 헤메서 간다.
- 훑기도 잘 훑으면서 더 좋은 방향으로 갈 수 없을까?

스텝사이즈(learning rate)도 문제가 된다.
- 너무 크면 최적을 못 찾아낼 수 있다.
- 너무 작으면 오래걸리게 된다.

적절한 크기가 필요

SGD를 개선하여 더 멋진 Optimizer가 많다.

![](https://i.imgur.com/Q6uZbyZ.png)

##### 잘 모르겠으면 ADAM

- 제일 유명하니까 쓰면 유리하다 : 너 왜 이거썼어?


##### SGD가 빠른데 좀 헤맨다.
##### SGD의 개선된 버전을 골라 더 빠르고 정확하게


#### 겨우 되어도 융통성이 없다?

- 고양이 모양을 봐도 뚱뚱하거나 색이다르면 고양이인지 모른다.

뉴럴넷에서 융통성을 기르는 방법 : Drop Out
- 학습 시킬 때 일부러 정보를 누락시키거나 중간 중간 노드를 끊는다.
- 자동차 사진에서 바퀴도 가리고 조금씩 가리며 학습하낟.

dropout으로 일부에 집착하지 않고 중요한 요소가 무엇인지 터득해 나간다.

##### 융통성 문제 : Drop out으로 유연성 획득


#### 문제의 유형에 따라 적덜한 아키텍쳐

스냅샷성 데이터 : 이미지 영상, 바둑> -> CNN
시퀀스성 데이터 : 음성, 언어, 주식가격, 맥락 -> RNN or LSTM

VGG도 유명한 CNN 구조 중 하나
- 유명한 녀석 : AlexNet(구형) - 이제 아무도 안씀
- VGG 인기많고 많이 씀	: 좀 지났지만 그냥 쓰기 좋다
- GoogleNet : 인기 없다가 Inception 버전업이 좀 씀 (이거 두개)
- ResNet : 레이어 짱 많음, 최근 많이 쓰임			(요새 유행)

ILSVRC : 영상 인식 관련 대회 : ImageNet 대회

VGG가 상위권으로 올라와 주목받음 : 실제 1등은 googlenet이었지만 인기는 VGG가..

VGG는 구조가 직관적이고 성능도 쓸만해서 많이 쓰임

convolution과 pooling을 반복한다
- 그림을 눈앞 1cm거리에서 본다 ; 점 선 질감만 보임
- 점선 질감이합쳐저 삼각형 원 사각형 등이 보인다.
- 삼각형 원 사각형을 모아보니 귀 눈 발이 보인다.
- 더 멀리서 보니 하나로 모아져서 고양이가 보인다.

=> 조각을 보고 패턴을 익히고 점점 멀리서 조합을 본다. : 이방법을 흉내내면 컴퓨터도 그림을 잘 ㅁ볼수 있지 않을까?

계산적 측면에도
- 뉴럴세능 서로가 서로에게 전부 다 연결되어 있는데 이러다 보니 맞춰야할 weight가 많다.
- 이미지에서 인근 픽셀끼리만 묶어서 계산 : 계산량이 줄어든다.

Convolution : 특정 패턴이 있는지 박스로 훑으며 마킹
- 위아래선 필터, 좌우선피렅, 대각선필터, 동그라미필터 등등 여러가지 조각 필터로 해당 패턴이 그림 위에 있는지 확인한다.
- Convolution 박스로 밀고나면 숫자가 나옴 : 그 숫자를 Activation(주로 ReLU)에 넣어 나온 값.

zero padding 귀퉁이가 안짤리가 테두리에 추가

Convolution의 ㅏㅈㅇ점 : 간단한 필터들이 쌓여가며 엄청나게 복잡한 필터를 만들어 나간다.
- 부품을 조립해 더 복잡한 부품을 만든다.

점점 더 멀리서 보는건 어떻게 할까?
- 우리가 멀어져도 되지만 그림을 줄여도 되겠다.

그림을 줄이는 방법 : Max Pooling
- n x n(Pool)을 중요한 정보(가장 큰 값) 한 개로 줄인다. : 선명한 정보만 남아 판단과 학습이 쉬워지고 노이즈가 줄면서 덤으로 융통성 확보 된다.
- 보통 2x2로 ㅗ하면 전역에 적용
- stride라고 해서 좌우로 몇칸씩 뛸지 : 보통 2x2로 -> 절반씩 줄어든다.

패턴을 쌓아가며 점차 복잡한 패턴을 인식한다 : 사이즈를 줄여가며 더욱 추상화 해 나간다.

[한번 보세요 과정이 나옴](http://yosinski.com/deepvis)


![](https://i.imgur.com/YrQzrej.png)





